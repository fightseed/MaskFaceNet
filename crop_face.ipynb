{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mtcnn in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (0.1.0)\n",
      "Requirement already satisfied: keras>=2.0.0 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from mtcnn) (2.2.4)\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from mtcnn) (4.2.0.32)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn) (5.3.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
      "Requirement already satisfied: h5py in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn) (1.18.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn) (1.1.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn) (1.14.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pyplot (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for pyplot\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mtcnn\n",
    "!pip install pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "0.1.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import mtcnn\n",
    "# print version\n",
    "print(mtcnn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./dataset/images/n000001/0005_01.jpg', './dataset/images/n000001/0001_01.jpg', './dataset/images/n000001/0001_01_surgical.jpg', './dataset/images/n000001/0003_01.jpg', './dataset/images/n000001/0002_01.jpg', './dataset/images/n000001/0004_01.jpg', './dataset/images/n000002/0005_01.jpg', './dataset/images/n000002/0001_01.jpg', './dataset/images/n000002/0003_01.jpg', './dataset/images/n000002/0004_01.jpg']\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "data_path = \"./dataset/images\"\n",
    "data_files = glob('{}/**/*.jpg'.format(data_path))\n",
    "print(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_name= ['.', 'dataset', 'images', 'n000001', '0005_01.jpg']\n",
      "out_file= ./dataset/images_cropped/n000001/0005_01.jpg\n",
      "path_name= ['.', 'dataset', 'images', 'n000001', '0001_01.jpg']\n",
      "out_file= ./dataset/images_cropped/n000001/0001_01.jpg\n",
      "path_name= ['.', 'dataset', 'images', 'n000001', '0001_01_surgical.jpg']\n",
      "out_file= ./dataset/images_cropped/n000001/0001_01_surgical.jpg\n",
      "path_name= ['.', 'dataset', 'images', 'n000001', '0003_01.jpg']\n",
      "out_file= ./dataset/images_cropped/n000001/0003_01.jpg\n",
      "path_name= ['.', 'dataset', 'images', 'n000001', '0002_01.jpg']\n",
      "out_file= ./dataset/images_cropped/n000001/0002_01.jpg\n",
      "path_name= ['.', 'dataset', 'images', 'n000001', '0004_01.jpg']\n",
      "out_file= ./dataset/images_cropped/n000001/0004_01.jpg\n",
      "path_name= ['.', 'dataset', 'images', 'n000002', '0005_01.jpg']\n",
      "out_file= ./dataset/images_cropped/n000002/0005_01.jpg\n",
      "path_name= ['.', 'dataset', 'images', 'n000002', '0001_01.jpg']\n",
      "out_file= ./dataset/images_cropped/n000002/0001_01.jpg\n",
      "path_name= ['.', 'dataset', 'images', 'n000002', '0003_01.jpg']\n",
      "out_file= ./dataset/images_cropped/n000002/0003_01.jpg\n",
      "path_name= ['.', 'dataset', 'images', 'n000002', '0004_01.jpg']\n",
      "out_file= ./dataset/images_cropped/n000002/0004_01.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set output path\n",
    "out_path = \"./dataset/images_cropped\"\n",
    "\n",
    "# create the detector using default weights\n",
    "detector = mtcnn.MTCNN()\n",
    "\n",
    "for filename in data_files:\n",
    "    # load image from file\n",
    "    path_names = filename.split('/')\n",
    "    print(\"path_name=\", path_names)\n",
    "    out_file = \"{}/{}/{}\".format(out_path, path_names[-2], path_names[-1])\n",
    "    print(\"out_file=\", out_file)\n",
    "    pixels = plt.imread(filename)\n",
    "    \n",
    "    # detec faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "    \n",
    "    # extract the bounding box from the first face\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    # extend the bounding box by a factor of 0.3\n",
    "    ext_width = int(width * 0.1 / 2)\n",
    "    ext_height = int(height * 0.1 / 2)\n",
    "    x1 -= ext_width\n",
    "    y1 -= ext_height\n",
    "    x2 += ext_width\n",
    "    y2 += ext_height\n",
    "    #print(\"x1:\", x1, \"y1\", y1, \"x2:\", x2, \"y2\", y2)\n",
    "    \n",
    "    # extract the face\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "    \n",
    "    # resize pixels to the model size\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize((224, 224))\n",
    "    \n",
    "    # write image to file\n",
    "    os.makedirs(os.path.dirname(out_file), exist_ok=True)\n",
    "    with open(out_file, \"w\") as f:\n",
    "        image.save(out_file)\n",
    "    #face_array = asarray(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
