{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance(embeddings, squared=False):\n",
    "    \"\"\"Compute the 2D matrix of distances between all the embeddings.\n",
    "\n",
    "    Args:\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        pairwise_distances: tensor of shape (batch_size, batch_size)\n",
    "    \"\"\"\n",
    "    # Get the dot product between all embeddings\n",
    "    # shape (batch_size, batch_size)\n",
    "    #dot_product = tf.matmul(embeddings, tf.transpose(embeddings))\n",
    "    dot_product = torch.matmul(embeddings, torch.transpose(embeddings, 0, 1))\n",
    "\n",
    "    # Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.\n",
    "    # This also provides more numerical stability (the diagonal of the result will be exactly 0).\n",
    "    # shape (batch_size,)\n",
    "    #square_norm = tf.diag_part(dot_product)\n",
    "    square_norm = torch.diagonal(dot_product, 0)\n",
    "\n",
    "    # Compute the pairwise distance matrix as we have:\n",
    "    # ||a - b||^2 = ||a||^2  - 2 <a, b> + ||b||^2\n",
    "    # shape (batch_size, batch_size)\n",
    "    #distances = tf.expand_dims(square_norm, 0) - 2.0 * dot_product + tf.expand_dims(square_norm, 1)\n",
    "    distances = torch.unsqueeze(square_norm, 0) - 2.0 * dot_product + torch.unsqueeze(square_norm, 1)\n",
    "    \n",
    "    # Because of computation errors, some distances might be negative so we put everything >= 0.0\n",
    "    #distances = tf.maximum(distances, 0.0)\n",
    "    distances = torch.max(distances, torch.zeros_like(distances))\n",
    "    distances = distances.float()\n",
    "\n",
    "    if not squared:\n",
    "        # Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal)\n",
    "        # we need to add a small epsilon where distances == 0.0\n",
    "        #mask = tf.to_float(tf.equal(distances, 0.0))\n",
    "        #distances = distances + mask * 1e-16\n",
    "        mask = (distances == 0.0).float()\n",
    "        distances = distances + mask * 1e-16\n",
    "\n",
    "        distances = torch.sqrt(distances)\n",
    "\n",
    "        # Correct the epsilon added: set the distances on the mask to be exactly 0.0\n",
    "        distances = distances * (1.0 - mask)\n",
    "\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_semihard_triplet_loss(labels, embeddings, margin=0.001, squared=False):\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "\n",
    "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
    "\n",
    "    Args:\n",
    "        labels: labels of the batch, of size (batch_size,)\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        margin: margin for triplet loss\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        triplet_loss: scalar tensor containing the triplet loss\n",
    "    \"\"\"\n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dist = pairwise_distance(embeddings, squared=squared)\n",
    "\n",
    "    # For each anchor, get the hardest positive\n",
    "    # First, we need to get a mask for every valid positive (they should have same label)\n",
    "    mask_anchor_positive = get_anchor_positive_triplet_mask(labels)\n",
    "    mask_anchor_positive = mask_anchor_positive\n",
    "\n",
    "    # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\n",
    "    anchor_positive_dist = torch.matmul(mask_anchor_positive, pairwise_dist)\n",
    "\n",
    "    # shape (batch_size, 1)\n",
    "    hardest_positive_dist = torch.reduce_max(anchor_positive_dist, axis=1, keepdims=True)\n",
    "\n",
    "    # For each anchor, get the hardest negative\n",
    "    # First, we need to get a mask for every valid negative (they should have different labels)\n",
    "    mask_anchor_negative = get_anchor_negative_triplet_mask(labels)\n",
    "    mask_anchor_negative = mask_anchor_negative.float()\n",
    "\n",
    "    # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\n",
    "    max_anchor_negative_dist = torch.reduce_max(pairwise_dist, axis=1, keepdims=True)\n",
    "    anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)\n",
    "\n",
    "    # shape (batch_size,)\n",
    "    hardest_negative_dist = torch.reduce_min(anchor_negative_dist, axis=1, keepdims=True)\n",
    "\n",
    "    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "    triplet_loss = torch.max(hardest_positive_dist - hardest_negative_dist + margin, 0.0)\n",
    "\n",
    "    # Get final mean triplet loss\n",
    "    triplet_loss = torch.reduce_mean(triplet_loss)\n",
    "\n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HardTripletLoss(nn.Module):\n",
    "    \"\"\"Hard/Hardest Triplet Loss\n",
    "    (pytorch implementation of https://omoindrot.github.io/triplet-loss)\n",
    "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
    "    \"\"\"\n",
    "    def __init__(self, margin=0.1, hardest=False, squared=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            margin: margin for triplet loss\n",
    "            hardest: If true, loss is considered only hardest triplets.\n",
    "            squared: If true, output is the pairwise squared euclidean distance matrix.\n",
    "                If false, output is the pairwise euclidean distance matrix.\n",
    "        \"\"\"\n",
    "        super(HardTripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.hardest = hardest\n",
    "        self.squared = squared\n",
    "\n",
    "    def forward(self, embeddings, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            labels: labels of the batch, of size (batch_size,)\n",
    "            embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        Returns:\n",
    "            triplet_loss: scalar tensor containing the triplet loss\n",
    "        \"\"\"\n",
    "        # Make sure that labels only have identity and do not contain mask info.\n",
    "        assert( len(labels.shape) == 1 or (len(labels.shape) == 2 and labels.shape[-1] == 1) )\n",
    "        \n",
    "        pairwise_dist = self._pairwise_distance(embeddings, squared=self.squared)\n",
    "\n",
    "        if self.hardest:\n",
    "            # Get the hardest positive pairs\n",
    "            mask_anchor_positive = self._get_anchor_positive_triplet_mask(labels).float()\n",
    "            valid_positive_dist = pairwise_dist * mask_anchor_positive\n",
    "            hardest_positive_dist, _ = torch.max(valid_positive_dist, dim=1, keepdim=True)\n",
    "\n",
    "            # Get the hardest negative pairs\n",
    "            mask_anchor_negative = self._get_anchor_negative_triplet_mask(labels).float()\n",
    "            max_anchor_negative_dist, _ = torch.max(pairwise_dist, dim=1, keepdim=True)\n",
    "            anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (\n",
    "                    1.0 - mask_anchor_negative)\n",
    "            hardest_negative_dist, _ = torch.min(anchor_negative_dist, dim=1, keepdim=True)\n",
    "\n",
    "            # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "            triplet_loss = F.relu(hardest_positive_dist - hardest_negative_dist + self.margin)\n",
    "            triplet_loss = torch.mean(triplet_loss)\n",
    "        else:\n",
    "            anc_pos_dist = pairwise_dist.unsqueeze(dim=2)\n",
    "            anc_neg_dist = pairwise_dist.unsqueeze(dim=1)\n",
    "\n",
    "            # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n",
    "            # triplet_loss[i, j, k] will contain the triplet loss of anc=i, pos=j, neg=k\n",
    "            # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n",
    "            # and the 2nd (batch_size, 1, batch_size)\n",
    "            loss = anc_pos_dist - anc_neg_dist + self.margin\n",
    "\n",
    "            mask = self._get_triplet_mask(labels).float()\n",
    "            triplet_loss = loss * mask\n",
    "\n",
    "            # Remove negative losses (i.e. the easy triplets)\n",
    "            triplet_loss = F.relu(triplet_loss)\n",
    "\n",
    "            # Count number of hard triplets (where triplet_loss > 0)\n",
    "            hard_triplets = torch.gt(triplet_loss, 1e-16).float()\n",
    "            num_hard_triplets = torch.sum(hard_triplets)\n",
    "\n",
    "            triplet_loss = torch.sum(triplet_loss) / (num_hard_triplets + 1e-16)\n",
    "            \n",
    "        return triplet_loss\n",
    "\n",
    "\n",
    "    def _pairwise_distance(self, x, squared=False, eps=1e-16):\n",
    "        \"\"\" Compute the 2D matrix of distances between all the embeddings.\n",
    "        \"\"\"\n",
    "        cor_mat = torch.matmul(x, x.t())\n",
    "        norm_mat = cor_mat.diag()\n",
    "        distances = norm_mat.unsqueeze(1) - 2 * cor_mat + norm_mat.unsqueeze(0)\n",
    "        distances = F.relu(distances)\n",
    "\n",
    "        if not squared:\n",
    "            mask = torch.eq(distances, 0.0).float()\n",
    "            distances = distances + mask * eps\n",
    "            distances = torch.sqrt(distances)\n",
    "            distances = distances * (1.0 - mask)\n",
    "\n",
    "        return distances\n",
    "\n",
    "\n",
    "    def _get_anchor_positive_triplet_mask(self, labels):\n",
    "        \"\"\" Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\n",
    "        \"\"\"\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        indices_not_equal = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
    "\n",
    "        # Check if labels[i] == labels[j]\n",
    "        labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
    "\n",
    "        mask = indices_not_equal * labels_equal\n",
    "\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def _get_anchor_negative_triplet_mask(self, labels):\n",
    "        \"\"\" Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n",
    "        \"\"\"\n",
    "        # Check if labels[i] != labels[k]\n",
    "        labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
    "        mask = labels_equal ^ True\n",
    "        #mask = labels_equal ^ 1\n",
    "\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def _get_triplet_mask(self, labels):\n",
    "        \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
    "           A triplet (i, j, k) is valid if:\n",
    "             - i, j, k are distinct\n",
    "             - labels[i] == labels[j] and labels[i] != labels[k]\n",
    "        \"\"\"\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Check that i, j and k are distinct\n",
    "        indices_not_same = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
    "        i_not_equal_j = torch.unsqueeze(indices_not_same, 2)\n",
    "        i_not_equal_k = torch.unsqueeze(indices_not_same, 1)\n",
    "        j_not_equal_k = torch.unsqueeze(indices_not_same, 0)\n",
    "        distinct_indices = i_not_equal_j * i_not_equal_k * j_not_equal_k\n",
    "\n",
    "        # Check if labels[i] == labels[j] and labels[i] != labels[k]\n",
    "        label_equal = torch.eq(torch.unsqueeze(labels, 0), torch.unsqueeze(labels, 1))\n",
    "        i_equal_j = torch.unsqueeze(label_equal, 2)\n",
    "        i_equal_k = torch.unsqueeze(label_equal, 1)\n",
    "        \n",
    "        valid_labels = i_equal_j * (i_equal_k ^ True)\n",
    "        #valid_labels = i_equal_j * (i_equal_k ^ 1)\n",
    "\n",
    "        mask = distinct_indices * valid_labels   # Combine the two masks\n",
    "\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HardTripletLossWithMask(nn.Module):\n",
    "    \"\"\"Hard/Hardest Triplet Loss\n",
    "    (pytorch implementation of https://omoindrot.github.io/triplet-loss)\n",
    "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
    "    \"\"\"\n",
    "    def __init__(self, margin=0.1, hardest=False, squared=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            margin: margin for triplet loss\n",
    "            hardest: If true, loss is considered only hardest triplets.\n",
    "            squared: If true, output is the pairwise squared euclidean distance matrix.\n",
    "                If false, output is the pairwise euclidean distance matrix.\n",
    "        \"\"\"\n",
    "        super(HardTripletLossWithMask, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.hardest = hardest\n",
    "        self.squared = squared\n",
    "\n",
    "    def forward(self, embeddings, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            labels: labels of the batch, of size (batch_size,)\n",
    "            embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        Returns:\n",
    "            triplet_loss: scalar tensor containing the triplet loss\n",
    "        \"\"\"\n",
    "        # Make sure that labels contain both identity and mask info.\n",
    "        assert( len(labels.shape) == 2 and labels.shape[-1] == 2 )\n",
    "        labels, masked_faces = labels[:,0], labels[:,1]\n",
    "        \n",
    "        pairwise_dist = self._pairwise_distance(embeddings, squared=self.squared)\n",
    "\n",
    "        if self.hardest:\n",
    "            # Get the hardest positive pairs\n",
    "            mask_anchor_positive = self._get_anchor_positive_triplet_mask(labels).float()\n",
    "            valid_positive_dist = pairwise_dist * mask_anchor_positive\n",
    "            hardest_positive_dist, _ = torch.max(valid_positive_dist, dim=1, keepdim=True)\n",
    "\n",
    "            # Get the hardest negative pairs\n",
    "            mask_anchor_negative = self._get_anchor_negative_triplet_mask(labels).float()\n",
    "            max_anchor_negative_dist, _ = torch.max(pairwise_dist, dim=1, keepdim=True)\n",
    "            anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (\n",
    "                    1.0 - mask_anchor_negative)\n",
    "            hardest_negative_dist, _ = torch.min(anchor_negative_dist, dim=1, keepdim=True)\n",
    "\n",
    "            # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "            triplet_loss = F.relu(hardest_positive_dist - hardest_negative_dist + 0.1)\n",
    "            triplet_loss = torch.mean(triplet_loss)\n",
    "        else:\n",
    "            anc_pos_dist = pairwise_dist.unsqueeze(dim=2)\n",
    "            anc_neg_dist = pairwise_dist.unsqueeze(dim=1)\n",
    "\n",
    "            # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n",
    "            # triplet_loss[i, j, k] will contain the triplet loss of anc=i, pos=j, neg=k\n",
    "            # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n",
    "            # and the 2nd (batch_size, 1, batch_size)\n",
    "            triplet_loss = anc_pos_dist - anc_neg_dist\n",
    "            \n",
    "            # Get the masks for clear faces and masked faces\n",
    "            # Each mask is D^(m*m*m)\n",
    "            # mask[i,j,k] is 1 if {i,j,k} is a valid triplet where i:Anchor, j:Positive, k:negative\n",
    "            clear_face_mask, masked_face_mask = self._get_triplet_mask(labels, masked_faces)\n",
    "            clear_face_mask = clear_face_mask.float()\n",
    "            masked_face_mask = masked_face_mask.float()\n",
    "            \n",
    "            # Apply the masks\n",
    "            triplet_loss_clear  = triplet_loss * clear_face_mask\n",
    "            triplet_loss_masked = triplet_loss * masked_face_mask\n",
    "            \n",
    "            # Use broadcast to calculate the sums of the two triple losses along the 1st dimension\n",
    "            # The result is 4D: [m*m*m*m]\n",
    "            # Example: tl_clear(1,2,3) + tl_masked(1,4,5)...\n",
    "            # Use two 2D tensors as an example:\n",
    "            # |0 2 0|   |1 0 3|   |1 0 3|  |4 9  4|  |7  0 9 |\n",
    "            # |4 0 6| + |0 5 0| = |3 2 5|  |0 5  6|  |15 8 17|\n",
    "            # |0 8 0|   |7 0 9|   |1 0 3|, |6 11 6|, |7  0 9 |\n",
    "            loss = triplet_loss_clear.unsqueeze(2) + triplet_loss_masked.unsqueeze(1) + self.margin\n",
    "\n",
    "            # Remove negative losses (i.e. the easy triplets)\n",
    "            loss = F.relu(loss)\n",
    "\n",
    "            # Count number of hard triplets (where triplet_loss > 0)\n",
    "            hard_triplets = torch.gt(loss, 1e-16).float()\n",
    "            num_hard_triplets = torch.sum(hard_triplets)\n",
    "\n",
    "            loss = torch.sum(loss) / (num_hard_triplets + 1e-16)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def _pairwise_distance(self, x, squared=False, eps=1e-16):\n",
    "        \"\"\" Compute the 2D matrix of distances between all the embeddings.\n",
    "        \"\"\"\n",
    "        cor_mat = torch.matmul(x, x.t())\n",
    "        norm_mat = cor_mat.diag()\n",
    "        distances = norm_mat.unsqueeze(1) - 2 * cor_mat + norm_mat.unsqueeze(0)\n",
    "        distances = F.relu(distances)\n",
    "\n",
    "        if not squared:\n",
    "            mask = torch.eq(distances, 0.0).float()\n",
    "            distances = distances + mask * eps\n",
    "            distances = torch.sqrt(distances)\n",
    "            distances = distances * (1.0 - mask)\n",
    "\n",
    "        return distances\n",
    "\n",
    "\n",
    "    def _get_anchor_positive_triplet_mask(self, labels):\n",
    "        \"\"\" Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\n",
    "        \"\"\"\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        indices_not_equal = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
    "\n",
    "        # Check if labels[i] == labels[j]\n",
    "        labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
    "\n",
    "        mask = indices_not_equal * labels_equal\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def _get_anchor_positive_masked_triplet_mask(self, the_labels):\n",
    "        \"\"\" Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\n",
    "        \"\"\"\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        labels = the_labels.t()[0]\n",
    "        indices_not_equal = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
    "\n",
    "        # Check if labels[i] == labels[j]\n",
    "        labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
    "\n",
    "        mask = indices_not_equal * labels_equal\n",
    "\n",
    "        masked_faces = the_labels[:, 1:] == True\n",
    "        \n",
    "        return mask\n",
    "\n",
    "    def _get_anchor_negative_triplet_mask(self, labels):\n",
    "        \"\"\" Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n",
    "        \"\"\"\n",
    "        # Check if labels[i] != labels[k]\n",
    "        labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
    "        mask = labels_equal ^ 1\n",
    "\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def _get_triplet_mask(self, labels, masked_faces):\n",
    "        \"\"\"Return Two 3D masks (clear_face_mask and masked_face_mask)\n",
    "           where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
    "           A triplet (i, j, k) is valid if:\n",
    "             - i, j, k are distinct\n",
    "             - idens[i] == idens[j] and idens[i] != idens[k]\n",
    "             - masked_faces[j] == False and masked_faces[k] == False FOR clear_face_mask\n",
    "             - masked_faces[j] == True and masked_faces[k] == True FOR masked_face_mask\n",
    "             \n",
    "        \"\"\"\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Check that i, j and k are distinct\n",
    "        indices_not_same = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
    "        i_not_equal_j = torch.unsqueeze(indices_not_same, 2)\n",
    "        i_not_equal_k = torch.unsqueeze(indices_not_same, 1)\n",
    "        j_not_equal_k = torch.unsqueeze(indices_not_same, 0)\n",
    "        distinct_indices = i_not_equal_j * i_not_equal_k * j_not_equal_k\n",
    "\n",
    "        # Check if labels[i] == labels[j] and labels[i] != labels[k]\n",
    "        label_equal = torch.eq(torch.unsqueeze(labels, 0), torch.unsqueeze(labels, 1))\n",
    "        i_equal_j = torch.unsqueeze(label_equal, 2)\n",
    "        i_equal_k = torch.unsqueeze(label_equal, 1)\n",
    "        valid_labels = i_equal_j * (i_equal_k ^ True)\n",
    "        #valid_labels = i_equal_j * (i_equal_k ^ 1)\n",
    "        \n",
    "        # Check if masked_faces[j] == False and masked_faces[k] = False\n",
    "        mf = masked_faces.unsqueeze(1) * masked_faces\n",
    "        masked = mf.unsqueeze(2) * masked_faces\n",
    "        clear = masked ^ 1\n",
    "\n",
    "        # Combine the 3 masks\n",
    "        clear_face_mask = distinct_indices * valid_labels * clear\n",
    "        masked_face_mask = distinct_indices * valid_labels * masked\n",
    "\n",
    "        return clear_face_mask, masked_face_mask\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_latest_p37]",
   "language": "python",
   "name": "conda-env-pytorch_latest_p37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
