{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load face image dataset.\n",
    "\"\"\"\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#np.random.seed(1)\n",
    "def load_data(data_path=\"./data/test_masked_cloth_cropped\", train_size=460, val_size=20, test_size=20,\n",
    "              batch_size=120, use_mask=True, label_mask=False, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Load dataset and split into train, val and test.\n",
    "    Args:\n",
    "        path: (string) data path\n",
    "        train_size: (int) training set size\n",
    "        val_size: (int) validation set size\n",
    "        test_size: (int) test set size\n",
    "        batch_size: (int) batch size\n",
    "        use_gpu: (bool) use gpu or not\n",
    "    Return:\n",
    "        out: (tuple) (train_dset, val_dset, test_dset), (train_loader, val_loader, test_loader)\n",
    "    \"\"\"\n",
    "    idens_paths = glob.glob('{}/*'.format(data_path))\n",
    "    idens = [ path.split('/')[-1] for path in idens_paths]\n",
    "    np.random.shuffle(idens)\n",
    "    print(len(idens))\n",
    "    \n",
    "    train_dset = CustomDataset(data_path, idens[:train_size], batch_size, use_mask, label_mask, use_gpu=use_gpu)\n",
    "    val_dset   = CustomDataset(data_path, idens[train_size: train_size + val_size], batch_size, use_mask, label_mask, use_gpu=use_gpu)\n",
    "    test_dset  = CustomDataset(data_path, idens[train_size + val_size:], batch_size, use_mask, label_mask, use_gpu=use_gpu)\n",
    "    \n",
    "    print('train_set:{}, val_set:{}, test_set:{}'.format(train_dset.size, val_dset.size, test_dset.size))\n",
    "    train_loader = DataLoader(train_dset, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_dset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return (train_dset, val_dset, test_dset), (train_loader, val_loader, test_loader)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custome dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path, idens, batch_size, use_mask=True, label_mask=False, img_size=224, use_gpu=True):\n",
    "        self.data_path = data_path\n",
    "        self.idens = idens\n",
    "        self.n_idens = len(idens)\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.use_mask = use_mask\n",
    "        self.label_mask = label_mask\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        # dict {iden => [clear_img_filename,...]\n",
    "        self.iden_clear_faces = {}\n",
    "        # dict {iden => [masked_img_filename,...]\n",
    "        self.iden_masked_faces = {}\n",
    "        \n",
    "        # A estimate size, it is ok if not accurate\n",
    "        # use self.n_idens * 10 for debugging\n",
    "        self.size = self.n_idens * 100\n",
    "        \n",
    "        # Array of current batch data\n",
    "        self.batch_data = []\n",
    "    \n",
    "        # Current batch count\n",
    "        self.batch_count = None\n",
    "    \n",
    "    def _new_batch(self):\n",
    "        \"\"\" \n",
    "        Each batch has 3 identities, each identity has \n",
    "        3 clear face images and 3 masked face images.\n",
    "        \n",
    "        batch_size = idens_per_batch * clear_per_iden * masked_per_iden\n",
    "        num_iteration = self.size / batch_size\n",
    "        \"\"\"\n",
    "        \n",
    "        idens_per_batch = min(self.n_idens, 20)\n",
    "        \n",
    "        if self.use_mask:\n",
    "            clear_per_iden  = 3\n",
    "            masked_per_iden = 3\n",
    "        else:\n",
    "            clear_per_iden  = 6\n",
    "            masked_per_iden = 0\n",
    "        \n",
    "        self.batch_data, batch_data = [], []\n",
    "        idens = [ self.idens[idx] for idx in random.sample(range(self.n_idens), idens_per_batch) ]\n",
    "        \n",
    "        for nid, iden in enumerate(idens, start=1):\n",
    "            # nid (int): identity id within current batch\n",
    "            # iden (string): identity\n",
    "            if iden in self.iden_clear_faces:\n",
    "                clears = self.iden_clear_faces[iden]\n",
    "                masks = self.iden_masked_faces[iden]\n",
    "            else:\n",
    "                # Lazy load images for given identity\n",
    "                clears = glob.glob('{}/{}/*_*.jpg'.format(self.data_path, iden))\n",
    "                self.iden_clear_faces[iden] = clears\n",
    "                masks = glob.glob('{}/{}/*_*_*.jpg'.format(self.data_path, iden))\n",
    "                self.iden_masked_faces[iden] = masks\n",
    "\n",
    "            if self.use_mask:\n",
    "                if self.label_mask:\n",
    "                    batch_data.extend([\n",
    "                        (clears[idx], (nid, False)) for idx in random.sample(range(len(clears)), clear_per_iden) ])\n",
    "                    batch_data.extend([\n",
    "                        (masks[idx], (nid, True))   for idx in random.sample(range(len(masks)), masked_per_iden) ])\n",
    "                else:\n",
    "                    batch_data.extend([\n",
    "                        (clears[idx], nid) for idx in random.sample(range(len(clears)), clear_per_iden) ])\n",
    "                    batch_data.extend([\n",
    "                        (masks[idx], nid)   for idx in random.sample(range(len(masks)), masked_per_iden) ])\n",
    "            else:\n",
    "                batch_data.extend([\n",
    "                    (clears[idx], nid) for idx in random.sample(range(len(clears)), clear_per_iden) ])\n",
    "        \n",
    "        np.random.shuffle(batch_data)\n",
    "        self.batch_data = batch_data\n",
    " \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" input format (image, (identity (string), masked (bool))\n",
    "        \"\"\"\n",
    "        batch_count = int(idx / self.batch_size)\n",
    "        b_idx = idx % self.batch_size\n",
    "        if batch_count != self.batch_count:\n",
    "            self.batch_count = batch_count\n",
    "            self._new_batch()\n",
    "        \n",
    "        filename, label = self.batch_data[b_idx]\n",
    "        input_image = Image.open(filename)\n",
    "        preprocess = transforms.Compose([\n",
    "            # Not needed for now\n",
    "            #transforms.Resize(256),\n",
    "            #transforms.CenterCrop(224),\n",
    "            \n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        input_tensor = preprocess(input_image)\n",
    "        label_tensor = torch.tensor(label)\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            input_tensor = input_tensor.to('cuda')\n",
    "            label_tensor = label_tensor.to('cuda')\n",
    "\n",
    "        return input_tensor, label_tensor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_latest_p37]",
   "language": "python",
   "name": "conda-env-pytorch_latest_p37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
