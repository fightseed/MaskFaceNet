{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.3.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.33.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.11.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.7.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.4.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (0.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (3.3.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (45.2.0.post20200210)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.18.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard) (1.14.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.6.20)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (2.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (2.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: torchsummary in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install numpy\n",
    "# !pip install torch\n",
    "# !pip install tqdm\n",
    "!pip install tensorboard\n",
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchsummary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_size=1600, val_size=400, test_size=100, batch_size=32, use_gpu=True):\n",
    "    data_path = \"./dataset\"\n",
    "    data_files = glob('{}/**/*.jpg'.format(data_path))\n",
    "    np.random.shuffle(data_files)\n",
    "    \n",
    "    train_dset = CustomDataset(data_files[:train_size], train_size, use_gpu=use_gpu)\n",
    "    val_dset = CustomDataset(data_files[train_size: train_size + val_size], val_size, use_gpu=use_gpu)\n",
    "    test_dset = CustomDataset(data_files[train_size + val_size:]test_size, use_gpu=use_gpu)\n",
    "    train_loader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return (train_dset, val_dset, test_dset), (train_loader, val_loader, test_loader)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_files, size, img_size=224, use_gpu=True):\n",
    "        self.size = size\n",
    "        self.use_gpu = use_gpu\n",
    "        self.data_files = data_files\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = data_files[idx]\n",
    "        path_names = filename.split('/')\n",
    "        identity = int(path_names[-2])\n",
    "        img = plt.imread(filename)\n",
    "        img = img / 255.0\n",
    "        img = torch.from_numpy(img)\n",
    "        img = img.type(torch.FloatTensor)\n",
    "        if self.use_gpu:\n",
    "            img = img.cuda()\n",
    "\n",
    "        # Convert from (height, width, channels) to (channels, height, width)\n",
    "        # as input to the network.\n",
    "        # height, width, channels = img.shape\n",
    "        # img = img.view((channels, height, width))\n",
    "        # img = img.permute(2, 0, 1)\n",
    "        return (img, identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(VGG16, self).__init__()\n",
    "        # conv layers: (in_channel size, out_channels size, kernel_size, stride, padding)\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        # max pooling (kernel_size, stride)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # fully conected layers:\n",
    "        self.fc6 = nn.Linear(7*7*512, 4096)\n",
    "        self.fc7 = nn.Linear(4096, 4096)\n",
    "        #self.fc8 = nn.Linear(4096, 1000)\n",
    "        self.fc8 = nn.Linear(4096, n_classes)\n",
    "\n",
    "    def forward(self, x, training=True):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 7 * 7 * 512)\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.dropout(x, 0.5, training=training)\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = F.dropout(x, 0.5, training=training)\n",
    "        x = self.fc8(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        # a function to predict the labels of a batch of inputs\n",
    "        x = F.softmax(self.forward(x, training=False))\n",
    "        return x\n",
    "\n",
    "    def accuracy(self, x, y):\n",
    "        # a function to calculate the accuracy of label prediction for a batch of inputs\n",
    "        #   x: a batch of inputs\n",
    "        #   y: the true labels associated with x\n",
    "        prediction = self.predict(x)\n",
    "        maxs, indices = torch.max(prediction, 1)\n",
    "        acc = 100 * torch.sum(torch.eq(indices.float(), y.float()).float())/y.size()[0]\n",
    "        return acc.cpu().data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3cf6696765cb32df\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3cf6696765cb32df\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 9007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Tensorboard\n",
    "%load_ext tensorboard\n",
    "#%tensorboard --logdir ./runs\n",
    "%tensorboard --logdir ./runs --host localhost --port 9007\n",
    "#%tensorboard --logdir ./runs --host 0.0.0.0 --port 9007\n",
    "#%load_ext tensorboard %tensorboard --logdir /tf/notebooks/graphs --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, loaders, writer, num_epochs=10):\n",
    "    train_loader, val_loader, test_loader = loaders\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        nsamples = 0\n",
    "        with tqdm(train_loader) as t:\n",
    "            for i, (img, mask) in enumerate(t):\n",
    "                t.set_description(f'Train Iter {i+1}/{len(train_loader)}')\n",
    "                loss, metrics = take_training_step(img, mask, model, optimizer)\n",
    "                train_loss += metrics\n",
    "                nsamples += img.size(0)\n",
    "                t.set_postfix(mb_loss=loss.item(), run_loss=train_loss/nsamples)\n",
    "                writer.add_scalar('Loss/train', loss.item(), i + epoch * len(train_loader))\n",
    "\n",
    "        test_model(model, \"Val\", val_loader, writer, epoch+1, max_show=3)\n",
    "        print()\n",
    "\n",
    "def test_model_loss(model, loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    nsamples = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (img, mask) in enumerate(tqdm(loader)):\n",
    "            outputs = model(img)\n",
    "            loss, metric = calc_loss(outputs, mask)\n",
    "            test_loss += metric\n",
    "            nsamples += img.size(0)\n",
    "        return test_loss, nsamples\n",
    "\n",
    "def test_model(model, title, data_loader, writer, epoch, max_show=10):\n",
    "    test_loss, nsamples = test_model_loss(model, data_loader)\n",
    "    print(f\"{title} Loss: {test_loss/nsamples}\")\n",
    "\n",
    "    count = 0\n",
    "    for i, (img, mask) in enumerate(data_loader):\n",
    "        outputs = model(img)\n",
    "        for j in range(img.shape[0]):\n",
    "            count += 1\n",
    "            curr_img, curr_mask, curr_out = img[j], mask[j], outputs[j]\n",
    "            curr_out = torch.sigmoid(curr_out) >= 0.5\n",
    "            plot_img(curr_img, curr_mask, writer, epoch, pred=curr_out, torch=True, elem=j+i*img.shape[0])\n",
    "            if count >= max_show:\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance(embeddings, squared=False):\n",
    "    \"\"\"Compute the 2D matrix of distances between all the embeddings.\n",
    "\n",
    "    Args:\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        pairwise_distances: tensor of shape (batch_size, batch_size)\n",
    "    \"\"\"\n",
    "    # Get the dot product between all embeddings\n",
    "    # shape (batch_size, batch_size)\n",
    "    #dot_product = tf.matmul(embeddings, tf.transpose(embeddings))\n",
    "    dot_product = torch.matmul(embeddings, torch.transpose(embeddings, 0, 1))\n",
    "\n",
    "    # Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.\n",
    "    # This also provides more numerical stability (the diagonal of the result will be exactly 0).\n",
    "    # shape (batch_size,)\n",
    "    #square_norm = tf.diag_part(dot_product)\n",
    "    square_norm = torch.diagonal(dot_product, 0)\n",
    "\n",
    "    # Compute the pairwise distance matrix as we have:\n",
    "    # ||a - b||^2 = ||a||^2  - 2 <a, b> + ||b||^2\n",
    "    # shape (batch_size, batch_size)\n",
    "    #distances = tf.expand_dims(square_norm, 0) - 2.0 * dot_product + tf.expand_dims(square_norm, 1)\n",
    "    distances = torch.unsqueeze(square_norm, 0) - 2.0 * dot_product + torch.unsqueeze(square_norm, 1)\n",
    "    \n",
    "    # Because of computation errors, some distances might be negative so we put everything >= 0.0\n",
    "    #distances = tf.maximum(distances, 0.0)\n",
    "    distances = torch.max(distances, torch.zeros_like(distances))\n",
    "    distances = distances.float()\n",
    "\n",
    "    if not squared:\n",
    "        # Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal)\n",
    "        # we need to add a small epsilon where distances == 0.0\n",
    "        #mask = tf.to_float(tf.equal(distances, 0.0))\n",
    "        #distances = distances + mask * 1e-16\n",
    "        mask = (distances == 0.0).float()\n",
    "        distances = distances + mask * 1e-16\n",
    "\n",
    "        distances = torch.sqrt(distances)\n",
    "\n",
    "        # Correct the epsilon added: set the distances on the mask to be exactly 0.0\n",
    "        distances = distances * (1.0 - mask)\n",
    "\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_semihard_triplet_loss(labels, embeddings, margin=0.001, squared=False):\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "\n",
    "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
    "\n",
    "    Args:\n",
    "        labels: labels of the batch, of size (batch_size,)\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        margin: margin for triplet loss\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        triplet_loss: scalar tensor containing the triplet loss\n",
    "    \"\"\"\n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dist = pairwise_distance(embeddings, squared=squared)\n",
    "\n",
    "    # For each anchor, get the hardest positive\n",
    "    # First, we need to get a mask for every valid positive (they should have same label)\n",
    "    mask_anchor_positive = get_anchor_positive_triplet_mask(labels)\n",
    "    mask_anchor_positive = mask_anchor_positive)\n",
    "\n",
    "    # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\n",
    "    anchor_positive_dist = torch.matmul(mask_anchor_positive, pairwise_dist)\n",
    "\n",
    "    # shape (batch_size, 1)\n",
    "    hardest_positive_dist = torch.reduce_max(anchor_positive_dist, axis=1, keepdims=True)\n",
    "\n",
    "    # For each anchor, get the hardest negative\n",
    "    # First, we need to get a mask for every valid negative (they should have different labels)\n",
    "    mask_anchor_negative = get_anchor_negative_triplet_mask(labels)\n",
    "    mask_anchor_negative = mask_anchor_negative.float()\n",
    "\n",
    "    # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\n",
    "    max_anchor_negative_dist = torch.reduce_max(pairwise_dist, axis=1, keepdims=True)\n",
    "    anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)\n",
    "\n",
    "    # shape (batch_size,)\n",
    "    hardest_negative_dist = torch.reduce_min(anchor_negative_dist, axis=1, keepdims=True)\n",
    "\n",
    "    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "    triplet_loss = torch.max(hardest_positive_dist - hardest_negative_dist + margin, 0.0)\n",
    "\n",
    "    # Get final mean triplet loss\n",
    "    triplet_loss = torch.reduce_mean(triplet_loss)\n",
    "\n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HardTripletLoss(nn.Module):\n",
    "    \"\"\"Hard/Hardest Triplet Loss\n",
    "    (pytorch implementation of https://omoindrot.github.io/triplet-loss)\n",
    "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
    "    \"\"\"\n",
    "    def __init__(self, margin=0.1, hardest=False, squared=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            margin: margin for triplet loss\n",
    "            hardest: If true, loss is considered only hardest triplets.\n",
    "            squared: If true, output is the pairwise squared euclidean distance matrix.\n",
    "                If false, output is the pairwise euclidean distance matrix.\n",
    "        \"\"\"\n",
    "        super(HardTripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.hardest = hardest\n",
    "        self.squared = squared\n",
    "\n",
    "    def forward(self, embeddings, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            labels: labels of the batch, of size (batch_size,)\n",
    "            embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        Returns:\n",
    "            triplet_loss: scalar tensor containing the triplet loss\n",
    "        \"\"\"\n",
    "        pairwise_dist = _pairwise_distance(embeddings, squared=self.squared)\n",
    "\n",
    "        if self.hardest:\n",
    "            # Get the hardest positive pairs\n",
    "            mask_anchor_positive = _get_anchor_positive_triplet_mask(labels).float()\n",
    "            valid_positive_dist = pairwise_dist * mask_anchor_positive\n",
    "            hardest_positive_dist, _ = torch.max(valid_positive_dist, dim=1, keepdim=True)\n",
    "\n",
    "            # Get the hardest negative pairs\n",
    "            mask_anchor_negative = _get_anchor_negative_triplet_mask(labels).float()\n",
    "            max_anchor_negative_dist, _ = torch.max(pairwise_dist, dim=1, keepdim=True)\n",
    "            anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (\n",
    "                    1.0 - mask_anchor_negative)\n",
    "            hardest_negative_dist, _ = torch.min(anchor_negative_dist, dim=1, keepdim=True)\n",
    "\n",
    "            # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "            triplet_loss = F.relu(hardest_positive_dist - hardest_negative_dist + 0.1)\n",
    "            triplet_loss = torch.mean(triplet_loss)\n",
    "        else:\n",
    "            anc_pos_dist = pairwise_dist.unsqueeze(dim=2)\n",
    "            anc_neg_dist = pairwise_dist.unsqueeze(dim=1)\n",
    "\n",
    "            # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n",
    "            # triplet_loss[i, j, k] will contain the triplet loss of anc=i, pos=j, neg=k\n",
    "            # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n",
    "            # and the 2nd (batch_size, 1, batch_size)\n",
    "            loss = anc_pos_dist - anc_neg_dist + self.margin\n",
    "\n",
    "            mask = _get_triplet_mask(labels).float()\n",
    "            triplet_loss = loss * mask\n",
    "\n",
    "            # Remove negative losses (i.e. the easy triplets)\n",
    "            triplet_loss = F.relu(triplet_loss)\n",
    "\n",
    "            # Count number of hard triplets (where triplet_loss > 0)\n",
    "            hard_triplets = torch.gt(triplet_loss, 1e-16).float()\n",
    "            num_hard_triplets = torch.sum(hard_triplets)\n",
    "\n",
    "            triplet_loss = torch.sum(triplet_loss) / (num_hard_triplets + 1e-16)\n",
    "\n",
    "        return triplet_loss\n",
    "\n",
    "\n",
    "    def _pairwise_distance(x, squared=False, eps=1e-16):\n",
    "        # Compute the 2D matrix of distances between all the embeddings.\n",
    "\n",
    "        cor_mat = torch.matmul(x, x.t())\n",
    "        norm_mat = cor_mat.diag()\n",
    "        distances = norm_mat.unsqueeze(1) - 2 * cor_mat + norm_mat.unsqueeze(0)\n",
    "        distances = F.relu(distances)\n",
    "\n",
    "        if not squared:\n",
    "            mask = torch.eq(distances, 0.0).float()\n",
    "            distances = distances + mask * eps\n",
    "            distances = torch.sqrt(distances)\n",
    "            distances = distances * (1.0 - mask)\n",
    "\n",
    "        return distances\n",
    "\n",
    "\n",
    "    def _get_anchor_positive_triplet_mask(labels):\n",
    "        # Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\n",
    "\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        indices_not_equal = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
    "\n",
    "        # Check if labels[i] == labels[j]\n",
    "        labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
    "\n",
    "        mask = indices_not_equal * labels_equal\n",
    "\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def _get_anchor_negative_triplet_mask(labels):\n",
    "        # Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n",
    "\n",
    "        # Check if labels[i] != labels[k]\n",
    "        labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
    "        mask = labels_equal ^ 1\n",
    "\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def _get_triplet_mask(labels):\n",
    "        \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
    "        A triplet (i, j, k) is valid if:\n",
    "            - i, j, k are distinct\n",
    "            - labels[i] == labels[j] and labels[i] != labels[k]\n",
    "        \"\"\"\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Check that i, j and k are distinct\n",
    "        indices_not_same = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
    "        i_not_equal_j = torch.unsqueeze(indices_not_same, 2)\n",
    "        i_not_equal_k = torch.unsqueeze(indices_not_same, 1)\n",
    "        j_not_equal_k = torch.unsqueeze(indices_not_same, 0)\n",
    "        distinct_indices = i_not_equal_j * i_not_equal_k * j_not_equal_k\n",
    "\n",
    "        # Check if labels[i] == labels[j] and labels[i] != labels[k]\n",
    "        label_equal = torch.eq(torch.unsqueeze(labels, 0), torch.unsqueeze(labels, 1))\n",
    "        i_equal_j = torch.unsqueeze(label_equal, 2)\n",
    "        i_equal_k = torch.unsqueeze(label_equal, 1)\n",
    "        valid_labels = i_equal_j * (i_equal_k ^ 1)\n",
    "\n",
    "        mask = distinct_indices * valid_labels   # Combine the two masks\n",
    "\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(output, identities):\n",
    "    #bce = F.binary_cross_entropy_with_logits(yhat, ytrue)\n",
    "    #loss = bce.data.cpu().numpy()*yhat.size(0)\n",
    "    #return bce, loss\n",
    "    criterion = HardTripletLoss(margin=0.1).cuda()\n",
    "    triplet_loss = criterion(output, identities)\n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_training_step(img, identities, model, optimizer):\n",
    "    optimizer.zero_grad() #zhli\n",
    "    outputs = model(img)\n",
    "    loss, metrics = calc_loss(outputs, identities)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU? True\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    print(\"Using GPU?\", use_gpu)\n",
    "    datasets, loaders = load_data(use_gpu=use_gpu)\n",
    "    train_dset, val_dset, test_dset = datasets\n",
    "    train_loader, val_loader, test_loader = loaders\n",
    "\n",
    "    model = VGG16(512)\n",
    "    device = torch.device('cuda' if use_gpu else 'cpu')\n",
    "    model = model.to(device)\n",
    "    torchsummary.summary(model, input_size=(3, 192, 192))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "    train_model(model, optimizer, loaders, writer, num_epochs=10)\n",
    "    test_model(model, \"Test\", test_loader, writer, epoch=11)\n",
    "    writer.close()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
