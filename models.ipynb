{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Conv2d, BatchNorm1d, BatchNorm2d, PReLU, ReLU\n",
    "from torch.nn import Sigmoid, Dropout2d, Dropout, AvgPool2d, MaxPool2d\n",
    "from torch.nn import AdaptiveAvgPool2d, Sequential, Module, Parameter\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "############################################\n",
    "# VGG16 + Linear(in:1000, out:128) + L2Norm\n",
    "#\n",
    "class MaskedFaceNetVgg16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskedFaceNetVgg16,self).__init__()\n",
    "        self.vgg16 = models.vgg16(pretrained=False)\n",
    "        #self.net = self.vgg16.classifier\n",
    "        \n",
    "        # Linear layer to output 128bit embeddings.\n",
    "        self.linear = nn.Linear(1000, 128)\n",
    "        \n",
    "        #for p in self.net.parameters():\n",
    "        #    p.requires_grad=False\n",
    "\n",
    "    def forward(self,x):\n",
    "        #x = self.net(x)\n",
    "        x = self.vgg16(x)\n",
    "        x = self.linear(x)\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        return x\n",
    "\n",
    "###############################################\n",
    "# ResNet50 + Linear(in:1000, out:128) + L2Norm\n",
    "#\n",
    "class MaskedFaceNetResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskedFaceNetResNet50,self).__init__()\n",
    "        self.net = models.resnet50(pretrained=False)\n",
    "        \n",
    "        # Linear layer to output 128bit embeddings.\n",
    "        self.linear = nn.Linear(1000, 128)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.net(x)\n",
    "        x = self.linear(x)\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        return x\n",
    "\n",
    "########################################################\n",
    "# ResNet50 + DropOut + Linear(in:1000, out:512) + L2Norm\n",
    "#\n",
    "class MaskedFaceNetResNet50V2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskedFaceNetResNet50V2,self).__init__()\n",
    "        self.backbone = models.resnet50(pretrained=False)\n",
    "        \n",
    "        # Remove AveragePool and FC layers\n",
    "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n",
    "        #model.classifier = nn.Sequential(*[model.classifier[i] for i in range(4)])\n",
    "        \n",
    "        # embedding size 512 or 128\n",
    "        output_dim = 512\n",
    "        self.output_layer = Sequential(Dropout(0.6),\n",
    "                                       AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "                                       Flatten(),\n",
    "                                       Linear(in_features=2048, out_features=output_dim, bias=True),\n",
    "                                       BatchNorm1d(output_dim))\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.output_layer(x)\n",
    "        #x = F.normalize(x, p=2, dim=1)\n",
    "        x = l2_norm(x)\n",
    "        return x\n",
    "\n",
    "################################################\n",
    "# ResNet + Dropout + Linear + L2Norm\n",
    "# Inspired by InsightFace\n",
    "#\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "def l2_norm(input,axis=1):\n",
    "    norm = torch.norm(input,2,axis,True)\n",
    "    output = torch.div(input, norm)\n",
    "    return output\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = Conv2d(\n",
    "            channels, channels // reduction, kernel_size=1, padding=0 ,bias=False)\n",
    "        self.relu = ReLU(inplace=True)\n",
    "        self.fc2 = Conv2d(\n",
    "            channels // reduction, channels, kernel_size=1, padding=0 ,bias=False)\n",
    "        self.sigmoid = Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "class bottleneck_IR(nn.Module):\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(bottleneck_IR, self).__init__()\n",
    "        if in_channel == depth:\n",
    "            self.shortcut_layer = MaxPool2d(1, stride)\n",
    "        else:\n",
    "            self.shortcut_layer = Sequential(\n",
    "                Conv2d(in_channel, depth, (1, 1), stride ,bias=False), BatchNorm2d(depth))\n",
    "        self.res_layer = Sequential(\n",
    "            BatchNorm2d(in_channel),\n",
    "            Conv2d(in_channel, depth, (3, 3), (1, 1), 1 ,bias=False), PReLU(depth),\n",
    "            Conv2d(depth, depth, (3, 3), stride, 1 ,bias=False), BatchNorm2d(depth))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut_layer(x)\n",
    "        res = self.res_layer(x)\n",
    "        return res + shortcut\n",
    "\n",
    "class bottleneck_IR_SE(nn.Module):\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(bottleneck_IR_SE, self).__init__()\n",
    "        if in_channel == depth:\n",
    "            self.shortcut_layer = MaxPool2d(1, stride)\n",
    "        else:\n",
    "            self.shortcut_layer = Sequential(\n",
    "                Conv2d(in_channel, depth, (1, 1), stride ,bias=False), \n",
    "                BatchNorm2d(depth))\n",
    "        self.res_layer = Sequential(\n",
    "            BatchNorm2d(in_channel),\n",
    "            Conv2d(in_channel, depth, (3,3), (1,1),1 ,bias=False),\n",
    "            PReLU(depth),\n",
    "            Conv2d(depth, depth, (3,3), stride, 1 ,bias=False),\n",
    "            BatchNorm2d(depth),\n",
    "            SEModule(depth,16)\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        shortcut = self.shortcut_layer(x)\n",
    "        res = self.res_layer(x)\n",
    "        return res + shortcut\n",
    "\n",
    "class Bottleneck(namedtuple('Block', ['in_channel', 'depth', 'stride'])):\n",
    "    '''A named tuple describing a ResNet block.'''\n",
    "    \n",
    "def get_block(in_channel, depth, num_units, stride = 2):\n",
    "  return [Bottleneck(in_channel, depth, stride)] + [Bottleneck(depth, depth, 1) for i in range(num_units-1)]\n",
    "\n",
    "def get_blocks(num_layers):\n",
    "    if num_layers == 50:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units = 3),\n",
    "            get_block(in_channel=64, depth=128, num_units=4),\n",
    "            get_block(in_channel=128, depth=256, num_units=14),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 100:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=13),\n",
    "            get_block(in_channel=128, depth=256, num_units=30),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 152:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=8),\n",
    "            get_block(in_channel=128, depth=256, num_units=36),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    return blocks\n",
    "\n",
    "class MaskedFaceNetBackbone(Module):\n",
    "    def __init__(self, num_layers, drop_ratio, mode='ir'):\n",
    "        super(MaskedFaceNetBackbone, self).__init__()\n",
    "        assert num_layers in [50, 100, 152], 'num_layers should be 50,100, or 152'\n",
    "        assert mode in ['ir', 'ir_se'], 'mode should be ir or ir_se'\n",
    "        blocks = get_blocks(num_layers)\n",
    "        if mode == 'ir':\n",
    "            unit_module = bottleneck_IR\n",
    "        elif mode == 'ir_se':\n",
    "            unit_module = bottleneck_IR_SE\n",
    "        self.input_layer = Sequential(Conv2d(3, 64, (3, 3), 1, 1 ,bias=False), \n",
    "                                      BatchNorm2d(64), \n",
    "                                      PReLU(64))\n",
    "        self.output_layer = Sequential(BatchNorm2d(512), \n",
    "                                       Dropout(drop_ratio),\n",
    "                                       Flatten(),\n",
    "                                       Linear(512 * 7 * 7, 512),\n",
    "                                       BatchNorm1d(512))\n",
    "        modules = []\n",
    "        for block in blocks:\n",
    "            for bottleneck in block:\n",
    "                modules.append(\n",
    "                    unit_module(bottleneck.in_channel,\n",
    "                                bottleneck.depth,\n",
    "                                bottleneck.stride))\n",
    "        self.body = Sequential(*modules)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.body(x)\n",
    "        x = self.output_layer(x)\n",
    "        return l2_norm(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_latest_p37]",
   "language": "python",
   "name": "conda-env-pytorch_latest_p37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
